{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from   scipy import stats\n",
    "from   copy import deepcopy\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append('/Users/research/projects/alderaan/')\n",
    "from alderaan.utils import weighted_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc462e",
   "metadata": {},
   "source": [
    "# Generate synthetic posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPL = 100\n",
    "\n",
    "mu_true = stats.beta(0.9, 3.0).rvs(NPL)\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(NPL):\n",
    "    mu = mu_true[i]\n",
    "    \n",
    "    sd_p = 0.03\n",
    "    sd_n = 0.2\n",
    "    \n",
    "    d = pd.DataFrame(columns=['precise noisy try_sd try_mu'.split()])\n",
    "    d.precise = stats.truncnorm(-mu/sd_p, (1-mu)/sd_p, loc=mu, scale=sd_p).rvs(3000)\n",
    "    d.noisy   = stats.truncnorm(-mu/sd_n, (1-mu)/sd_n, loc=mu, scale=sd_n).rvs(3000)\n",
    "    d.try_sd  = stats.norm(loc=mu, scale=sd_n).rvs(3000)\n",
    "    d.try_mu  = stats.norm(loc=mu, scale=sd_n).rvs(3000) + np.random.normal(0, sd_n)\n",
    "    \n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cad01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "146bc3ce",
   "metadata": {},
   "source": [
    "## Run the hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226778ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aesara_theano_fallback.tensor as T\n",
    "from   aesara_theano_fallback import aesara as theano\n",
    "from   celerite2.theano import GaussianProcess\n",
    "from   celerite2.theano import terms as GPterms\n",
    "import pymc3 as pm\n",
    "import pymc3_ext as pmx\n",
    "import corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9499049",
   "metadata": {},
   "source": [
    "#### Beta distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BetaDistPDF(a, b, x, B=None):\n",
    "    '''\n",
    "    The beta function B can be precomputed to improve performance\n",
    "    This is necessary if looping over multiple realizations w/in a PyMC model\n",
    "    '''\n",
    "    if B is None:\n",
    "        B = T.gamma(a)*T.gamma(b)/T.gamma(a+b)\n",
    "        \n",
    "    return x**(a-1) * (1-x)**(b-1) / B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BetaDistLogPDF(a, b, x, ln_B=None):\n",
    "    '''\n",
    "    The ln(beta) function ln_B can be precomputed to improve performance\n",
    "    This is necessary if looping over multiple realizations w/in a PyMC model\n",
    "    '''\n",
    "    if ln_B is None:\n",
    "        ln_B = T.gammaln(a) + T.gammaln(b) - T.gammaln(a+b)\n",
    "        \n",
    "    return (a-1)*np.log(x) + (b-1)*np.log(1-x) - ln_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPL = len(data)\n",
    "Nbin = 100\n",
    "\n",
    "bin_edges = np.linspace(0, 1, Nbin+1)\n",
    "bin_widths = bin_edges[1:] - bin_edges[:-1] \n",
    "bin_centers = 0.5*(bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # hyperpriors from Gelman Baysian Data Analysis Chapter 5\n",
    "    x = pm.Uniform(\"x\", lower=0.01, upper=0.99)                     # x = a/(a+b) = mean\n",
    "    y = pm.Uniform(\"y\", lower=0.1, upper=10)                        # y = 1/sqrt(a+b) ~ 'inverse precision'\n",
    "    \n",
    "    a = pm.Deterministic(\"a\", x/y**2)\n",
    "    b = pm.Deterministic(\"b\", (1-x)/y**2)\n",
    "    \n",
    "    # precompute the beta function\n",
    "    ln_B = T.gammaln(a) + T.gammaln(b) - T.gammaln(a+b)\n",
    "    \n",
    "    # track the pdf for convenience\n",
    "    ln_pdf = pm.Deterministic(\"ln_pdf\", BetaDistLogPDF(a, b, bin_centers, ln_B=ln_B))\n",
    "    \n",
    "    X = [None]*NPL\n",
    "    C = [None]*NPL\n",
    "    Z = T.zeros(NPL, dtype='float')\n",
    "    \n",
    "    for i, d in enumerate(data):\n",
    "        X[i] = BetaDistLogPDF(a, b, d.noisy.values, ln_B=ln_B)\n",
    "        C[i] = T.max(X[i])\n",
    "        Z = T.set_subtensor(Z[i], C[i] + T.log(T.sum(T.exp(X[i]-C[i]))))\n",
    "    \n",
    "    # likelihood\n",
    "    pm.Potential(\"ln_like\", T.sum(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41257a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pmx.sample(tune=2000, draws=1000, chains=2, target_accept=0.9, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.exp(trace.posterior.ln_pdf.values)\n",
    "x = x.reshape(-1,x.shape[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(bin_centers, np.percentile(x, 16, axis=0), np.percentile(x, 84, axis=0), color='r', alpha=0.3)\n",
    "plt.plot(bin_centers, np.median(x, axis=0), color='r', lw=2, label='posterior')\n",
    "plt.plot(bin_centers, stats.beta(0.9,3.0).pdf(bin_centers), 'k--')\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, 1)\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"e\", fontsize=24)\n",
    "plt.ylabel(\"P(e)\", fontsize=24)\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e31f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = corner.corner(trace, var_names=['x', 'y'], truths=[0.9/3.9, 1/np.sqrt(3.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = corner.corner(trace, var_names=['a', 'b'], truths=[0.9, 3.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49dafa",
   "metadata": {},
   "source": [
    "#### Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a54ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormDistLogPDF(mu, sd, x):        \n",
    "    return -T.log(sd) -0.5*np.log(2*np.pi) - (x-mu)**2/(2*sd**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPL = len(data)\n",
    "Nbin = 100\n",
    "\n",
    "bin_edges = np.linspace(0, 1, Nbin+1)\n",
    "bin_widths = bin_edges[1:] - bin_edges[:-1] \n",
    "bin_centers = 0.5*(bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # hyperpriors\n",
    "    mu = pm.Uniform(\"mu\", lower=-1.0, upper=1.0)\n",
    "    sd = pm.HalfCauchy(\"sd\", beta=2.0)\n",
    "            \n",
    "    # track the pdf for convenience\n",
    "    ln_pdf = pm.Deterministic(\"ln_pdf\", NormDistLogPDF(mu, sd, bin_centers))\n",
    "    \n",
    "    X = [None]*NPL\n",
    "    C = [None]*NPL\n",
    "    Z = T.zeros(NPL, dtype='float')\n",
    "    \n",
    "    for i, d in enumerate(data):\n",
    "        X[i] = NormDistLogPDF(mu, sd, d.ECC.values)\n",
    "        C[i] = T.max(X[i])\n",
    "        Z = T.set_subtensor(Z[i], C[i] + T.log(T.sum(T.exp(X[i]-C[i]))))\n",
    "    \n",
    "    # likelihood\n",
    "    pm.Potential(\"ln_like\", T.sum(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b27721",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pmx.sample(tune=2000, draws=1000, chains=2, target_accept=0.9, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec54b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.exp(trace.posterior.ln_pdf.values)\n",
    "x = x.reshape(-1,x.shape[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(truth.ecc, color='lightgrey', bins=np.linspace(0,1,11), density=True, label='truth')\n",
    "plt.fill_between(bin_centers, np.percentile(x, 16, axis=0), np.percentile(x, 84, axis=0), color='r', alpha=0.3)\n",
    "plt.plot(bin_centers, np.median(x, axis=0), color='r', lw=2, label='posterior')\n",
    "plt.plot(bin_centers, stats.beta(0.9,3.0).pdf(bin_centers), 'k--')\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(0, 1)\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"e\", fontsize=24)\n",
    "plt.ylabel(\"P(e)\", fontsize=24)\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3307bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = corner.corner(trace, var_names=['mu', 'sd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f5dd6",
   "metadata": {},
   "source": [
    "#### Non-parametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPL = len(data)\n",
    "Nbin = 100\n",
    "\n",
    "bin_edges = np.linspace(-2, 2, Nbin+1)\n",
    "bin_widths = bin_edges[1:] - bin_edges[:-1] \n",
    "bin_centers = 0.5*(bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # hyperpriors on GP\n",
    "    log_s = pm.Uniform(\"log_s\", lower=-1, upper=5, testval=0)\n",
    "    log_r = pm.Uniform(\"log_r\", lower=-1, upper=5, testval=0)\n",
    "    kernel = GPterms.Matern32Term(sigma=T.exp(log_s), rho=T.exp(log_r))\n",
    "    \n",
    "    # calculate bin heights from latent draws\n",
    "    latent = pm.Normal(\"latent\", mu=0, sd=1, shape=Nbin)\n",
    "    LS = T.exp(log_s)*latent\n",
    "\n",
    "    gp = GaussianProcess(kernel, mean=T.mean(LS))\n",
    "    gp.compute(bin_centers, diag=T.var(LS[1:]-LS[:-1])/T.sqrt(2)*T.ones(Nbin))\n",
    "    \n",
    "    beta  = gp.predict(LS)\n",
    "    ln_pdf = pm.Deterministic(\"ln_pdf\", beta - T.log(T.sum(T.exp(beta)*bin_widths)))\n",
    "    \n",
    "    # hierarchical model\n",
    "    X = [None]*NPL\n",
    "    C = [None]*NPL\n",
    "    Z = T.zeros(NPL, dtype='float')\n",
    "    \n",
    "    for i, d in enumerate(data):\n",
    "        inds = np.digitize(d.try_mu.values, bin_edges[1:], right=True)\n",
    "        X[i] = ln_pdf[inds]\n",
    "        C[i] = T.max(X[i])\n",
    "        Z = T.set_subtensor(Z[i], C[i] + T.log(T.sum(T.exp(X[i]-C[i]))))\n",
    "    \n",
    "    # likelihood\n",
    "    pm.Potential(\"ln_like\", T.sum(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9934cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pmx.sample(tune=2000, draws=1000, chains=2, target_accept=0.9, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.exp(trace.posterior.ln_pdf.values)\n",
    "x = x.reshape(-1,x.shape[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(bin_centers, np.percentile(x, 16, axis=0), np.percentile(x, 84, axis=0), color='r', alpha=0.3)\n",
    "plt.plot(bin_centers, np.median(x, axis=0), color='r', lw=2, label='posterior')\n",
    "plt.plot(bin_centers, stats.beta(0.9,3.0).pdf(bin_centers), 'k--')\n",
    "plt.ylim(0, None)\n",
    "plt.xlim(-0.1, 1)\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"e\", fontsize=24)\n",
    "plt.ylabel(\"P(e)\", fontsize=24)\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3852459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = corner.corner(trace, var_names=['log_s', 'log_r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817593f6",
   "metadata": {},
   "source": [
    "## Re-weight posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac548e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = 'koi ror b T14'.split()\n",
    "simulated = {}\n",
    "posterior = {}\n",
    "\n",
    "for k in keys:\n",
    "    simulated[k] = np.zeros(len(results), dtype='float')\n",
    "    posterior[k+'_16'] = np.zeros(len(results), dtype='float')\n",
    "    posterior[k+'_50'] = np.zeros(len(results), dtype='float')\n",
    "    posterior[k+'_84'] = np.zeros(len(results), dtype='float')\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    koi = 'K' + results[i].target[1:]\n",
    "    use = truth.koi_id == koi\n",
    "    \n",
    "    w = d.WEIGHTS.values * stats.beta(1.3, 2.7).pdf(d.ECC.values)\n",
    "    w /= np.sum(w)\n",
    "\n",
    "    simulated['ror'][i] = truth[use].ror\n",
    "    simulated['b'][i] = truth[use].impact\n",
    "    simulated['T14'][i] = truth[use].duration\n",
    "    \n",
    "    posterior['ror_16'][i] = weighted_percentile(d.ROR.values, 16, w=w)\n",
    "    posterior['ror_50'][i] = weighted_percentile(d.ROR.values, 50, w=w)\n",
    "    posterior['ror_84'][i] = weighted_percentile(d.ROR.values, 84, w=w)\n",
    "    \n",
    "    posterior['b_16'][i] = weighted_percentile(d.IMPACT.values, 16, w=w)\n",
    "    posterior['b_50'][i] = weighted_percentile(d.IMPACT.values, 50, w=w)\n",
    "    posterior['b_84'][i] = weighted_percentile(d.IMPACT.values, 84, w=w)\n",
    "    \n",
    "    posterior['T14_16'][i] = weighted_percentile(d.DUR14.values, 16, w=w)\n",
    "    posterior['T14_50'][i] = weighted_percentile(d.DUR14.values, 50, w=w)\n",
    "    posterior['T14_84'][i] = weighted_percentile(d.DUR14.values, 84, w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keys:\n",
    "    if k!= 'koi':\n",
    "        fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "        xmin = simulated[k].min()\n",
    "        xmax = simulated[k].max()\n",
    "        x = np.linspace(xmin, xmax)\n",
    "        \n",
    "        yerr1 = posterior[k+'_50'] - posterior[k+'_16']\n",
    "        yerr2 = posterior[k+'_84'] - posterior[k+'_50']\n",
    "        \n",
    "        zscore = (posterior[k+'_50'] - simulated[k])/(0.5*(posterior[k+'_84'] - posterior[k+'_16']))\n",
    "        \n",
    "        ax[0].errorbar(simulated[k], posterior[k+'_50'], yerr=(yerr1, yerr2), fmt='k.', alpha=0.5)\n",
    "        ax[0].plot(x, x, 'r:')\n",
    "        ax[0].set_xlabel(k, fontsize=20)\n",
    "        ax[0].set_xlim(xmin, xmax)\n",
    "        ax[0].set_ylim(0.9*xmin, 1.1*xmax)\n",
    "        ax[1].hist(zscore, bins=np.linspace(-5,5,21), color='lightgrey')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5022e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
